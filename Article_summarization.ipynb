{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install beautifulsoup4"
      ],
      "metadata": {
        "id": "0TPxJ_JJh7yv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lxml"
      ],
      "metadata": {
        "id": "_-7lGhCFh71Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import bs4 as bs\n",
        "import urllib.request\n",
        "import re\n",
        "scraped_data = urllib.request.urlopen('https://en.wikipedia.org/wiki/Artificial_intelligence')\n",
        "article = scraped_data.read()\n",
        "parsed_article = bs.BeautifulSoup(article,'lxml')\n",
        "paragraphs = parsed_article.find_all('p')\n",
        "article_text = \"\"\n",
        "for p in paragraphs:\n",
        "    article_text += p.text"
      ],
      "metadata": {
        "id": "hJ2atIhxh74Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing Square Brackets and Extra Spaces\n",
        "article_text = re.sub(r'\\[[0-9]*\\]', ' ', article_text)\n",
        "article_text = re.sub(r'\\s+', ' ', article_text)"
      ],
      "metadata": {
        "id": "UuGadpJRh764"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing special characters and digits\n",
        "formatted_article_text = re.sub('[^a-zA-Z]', ' ', article_text )\n",
        "formatted_article_text = re.sub(r'\\s+', ' ', formatted_article_text)"
      ],
      "metadata": {
        "id": "ElSMQLZliP5J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk"
      ],
      "metadata": {
        "id": "Tmd7RE0djaFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "nZzdOs8Cjgun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_list = nltk.sent_tokenize(article_text)"
      ],
      "metadata": {
        "id": "FU12bnZMiP9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "HmSVGuCQjo2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "word_frequencies = {}\n",
        "for word in nltk.word_tokenize(formatted_article_text):\n",
        "    if word not in stopwords:\n",
        "        if word not in word_frequencies.keys():\n",
        "            word_frequencies[word] = 1\n",
        "        else:\n",
        "            word_frequencies[word] += 1"
      ],
      "metadata": {
        "id": "ist1Td2TiP__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "maximum_frequncy = max(word_frequencies.values())\n",
        "\n",
        "for word in word_frequencies.keys():\n",
        "    word_frequencies[word] = (word_frequencies[word]/maximum_frequncy)"
      ],
      "metadata": {
        "id": "tEs2B0NRiQEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_scores = {}\n",
        "for sent in sentence_list:\n",
        "    for word in nltk.word_tokenize(sent.lower()):\n",
        "        if word in word_frequencies.keys():\n",
        "            if len(sent.split(' ')) < 30:\n",
        "                if sent not in sentence_scores.keys():\n",
        "                    sentence_scores[sent] = word_frequencies[word]\n",
        "                else:\n",
        "                    sentence_scores[sent] += word_frequencies[word]"
      ],
      "metadata": {
        "id": "_ZDRs1gOh79K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import heapq\n",
        "summary_sentences = heapq.nlargest(7, sentence_scores, key=sentence_scores.get)\n",
        "\n",
        "summary = ' '.join(summary_sentences)\n",
        "print(summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVxX8_8rich4",
        "outputId": "71f98ef6-a6f9-4090-a5a3-f8d965273874"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A machine with general intelligence can solve a wide variety of problems with breadth and versatility similar to human intelligence. Deep learning has drastically improved the performance of programs in many important subfields of artificial intelligence, including computer vision, speech recognition, image classification and others. A superintelligence, hyperintelligence, or superhuman intelligence, is a hypothetical agent that would possess intelligence far surpassing that of the brightest and most gifted human mind. AI founder John McCarthy agreed, writing that \"Artificial intelligence is not, by definition, simulation of human intelligence\". Many researchers began to doubt that the symbolic approach would be able to imitate all the processes of human cognition, especially perception, robotics, learning and pattern recognition.  Artificial intelligence (AI) is intelligence—perceiving, synthesizing, and inferring information—demonstrated by machines, as opposed to intelligence displayed by non-human animals and humans. Much of current research involves statistical AI, which is overwhelmingly used to solve specific problems, even highly successful techniques such as deep learning.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fixXd3OvicoB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DKdd8NGXic2f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}